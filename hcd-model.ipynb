{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Description\nThe goal of this project is to develop a machine learning model capable of identifying metastatic cancer in small image patches extracted from larger digital pathology scans. Metastatic cancer detection is crucial as it helps in early diagnosis and treatment planning, potentially improving patient outcomes. This task involves binary image classification, where each image patch is classified as either containing metastatic cancer (positive) or not (negative).\n\n## Dataset Description\nThe dataset used for this project is a slightly modified version of the PatchCamelyon (PCam) benchmark dataset, which is specifically designed for binary image classification tasks. The dataset consists of small image patches taken from larger digital pathology scans, and the task is to classify each patch as containing metastatic cancer or not.\n\nThe dataset provided for this project includes the following components:\n\n1. Train Folder: Contains a large number of .tif image files used for training the model.\n2. Test Folder: Contains a large number of .tif image files used for testing the model.\n3. sample_submission.csv: A sample submission file in CSV format that provides the structure required for submitting predictions on the test set to Kaggle.\n4. train_labels.csv: A CSV file containing the labels for the training images. It has two columns:\n- id: The identifier for each image (filename without extension).\n- label: The binary label indicating whether the image patch contains metastatic cancer (1) or not (0).","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport numpy as np\nfrom numpy.random import seed\nseed(123)\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\ntf.random.set_seed(123)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T00:33:36.938977Z","iopub.execute_input":"2024-08-07T00:33:36.939466Z","iopub.status.idle":"2024-08-07T00:33:52.919213Z","shell.execute_reply.started":"2024-08-07T00:33:36.939388Z","shell.execute_reply":"2024-08-07T00:33:52.918208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/histopathologic-cancer-detection')","metadata":{"execution":{"iopub.status.busy":"2024-08-07T00:33:52.920875Z","iopub.execute_input":"2024-08-07T00:33:52.921442Z","iopub.status.idle":"2024-08-07T00:33:52.929628Z","shell.execute_reply.started":"2024-08-07T00:33:52.921411Z","shell.execute_reply":"2024-08-07T00:33:52.928483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('../input/histopathologic-cancer-detection/train')))\nprint(len(os.listdir('../input/histopathologic-cancer-detection/test')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory Data Analysis (EDA) â€” Inspect, Visualize and Clean the Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\ndf_sample_submission = pd.read_csv('../input/histopathologic-cancer-detection/sample_submission.csv')\nprint(df_train.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# Visualize the distribution of labels\nsns.countplot(x='label', data=df_train)\nplt.title('Distribution of Labels in the Training Set')\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a few sample images from each class\nfig, axes = plt.subplots(2, 5, figsize=(20, 8))\n\n# Sample 5 images from class 0 (no cancer)\nfor i, img_id in enumerate(df_train[df_train['label'] == 0].sample(5)['id']):\n    img = cv2.imread(f'../input/histopathologic-cancer-detection/train/{img_id}.tif')\n    axes[0, i].imshow(img)\n    axes[0, i].set_title('Label: 0')\n    axes[0, i].axis('off')\n\n# Sample 5 images from class 1 (cancer)\nfor i, img_id in enumerate(df_train[df_train['label'] == 1].sample(5)['id']):\n    img = cv2.imread(f'../input/histopathologic-cancer-detection/train/{img_id}.tif')\n    axes[1, i].imshow(img)\n    axes[1, i].set_title('Label: 1')\n    axes[1, i].axis('off')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Data Cleaning Procedures","metadata":{}},{"cell_type":"code","source":"# Check for missing values\nmissing_values = df_train.isnull().sum()\nprint(missing_values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shuffling, Balancing, Splitting the Data","metadata":{}},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the number of samples available for each class\nlabel_counts = df_train['label'].value_counts()\nnum_samples = min(label_counts[0], label_counts[1], 500)\n\n# Sample the dataframes with the number of samples that can be safely drawn\ndf0 = df_train[df_train['label'] == 0].sample(num_samples)\ndf1 = df_train[df_train['label'] == 1].sample(num_samples)\n\n# Combine and shuffle the data\ndf_data = pd.concat([df0, df1], axis=0).reset_index(drop=True)\ndf_data = shuffle(df_data)\n\n# Verify the distribution of labels\nprint(df_data['label'].value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df_data['label']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.20, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('base')\nos.mkdir('base/train')\nos.mkdir('base/val')\nos.mkdir('base/train/0')\nos.mkdir('base/train/1')\nos.mkdir('base/val/0')\nos.mkdir('base/val/1')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image in list(df_train[df_train['label']==0]['id']):\n    shutil.copyfile('../input/histopathologic-cancer-detection/train/'+image+'.tif', 'base/train/0/'+image+'.tif')\n\nfor image in list(df_train[df_train['label']==1]['id']):\n    shutil.copyfile('../input/histopathologic-cancer-detection/train/'+image+'.tif', 'base/train/1/'+image+'.tif')\n    \nfor image in list(df_val[df_val['label']==0]['id']):\n    shutil.copyfile('../input/histopathologic-cancer-detection/train/'+image+'.tif', 'base/val/0/'+image+'.tif')\n    \nfor image in list(df_val[df_val['label']==1]['id']):\n    shutil.copyfile('../input/histopathologic-cancer-detection/train/'+image+'.tif', 'base/val/1/'+image+'.tif')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('base/train/0')))\nprint(len(os.listdir('base/train/1')))\nprint(len(os.listdir('base/val/0')))\nprint(len(os.listdir('base/val/1')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plan of Analysis\n\n### Data Preprocessing:\nNormalize the images to have pixel values between 0 and 1.\nAugment the data to enhance model generalization.\n\n### Model Development:\nUse a Convolutional Neural Network (CNN) model, which is well-suited for image classification tasks.\nExperiment with different architectures and hyperparameters to find the best-performing model.\nUse techniques such as early stopping, learning rate reduction, and model checkpointing to optimize the training process.\n\n### Model Evaluation:\nEvaluate the model using the validation set to monitor its performance and avoid overfitting.\nCalculate metrics such as accuracy, precision, recall, and F1-score to assess the model's performance comprehensively.\n\n### Submission:\nGenerate predictions on the test set.\nFormat the predictions according to the sample submission file and submit them to Kaggle for evaluation.","metadata":{}},{"cell_type":"code","source":"# Set up the generators\ntrain_path = 'base/train'\nvalid_path = 'base/val'\ntest_path = '../input/histopathologic-cancer-detection/test'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 10\nval_batch_size = 10\n\n\ntrain_steps = int(np.ceil(num_train_samples // train_batch_size))\nval_steps = int(np.ceil(num_val_samples // val_batch_size))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(96,96),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(valid_path,\n                                        target_size=(96,96),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\n# Note: shuffle=False causes the test dataset to not be shuffled\ntest_gen = datagen.flow_from_directory('../input/histopathologic-cancer-detection',\n                                        target_size=(96,96),\n                                        batch_size=1,\n                                        classes=['test'],\n                                        shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 64\nsecond_filters = 128\nthird_filters = 256\nfourth_filters = 512\n\ndropout_conv = 0.5\ndropout_dense = 0.5\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu',padding='same', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\n\nmodel.add(Conv2D(fourth_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(Conv2D(fourth_filters, kernel_size, activation ='relu',padding='same'))\nmodel.add(Conv2D(fourth_filters, kernel_size, activation ='relu',padding='same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(4096, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(2, activation = \"softmax\"))\n\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', \n              metrics=['AUC'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(val_gen.class_indices)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_gen, \n                    validation_data=val_gen,\n                    epochs=10, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture and Rationale\nThe model architecture proposed for the histopathologic cancer detection problem is a deep Convolutional Neural Network (CNN). CNNs are well-suited for image classification tasks because they can automatically learn and extract features from images through a series of convolutional layers.\n\n### Detailed architecture:\n\n1. Input Layer:\n- Input Shape: (96, 96, 3) for the resized image patches.\n- The input images are normalized to have pixel values between 0 and 1 using ImageDataGenerator with rescale=1.0/255.\n\n2. Convolutional Layers:\n- First Convolution Block:\n- 2 Conv2D layers with 64 filters, kernel size of (3,3), and ReLU activation.\n- MaxPooling2D layer with a pool size of (2,2).\n- Second Convolution Block:\n- 2 Conv2D layers with 128 filters, kernel size of (3,3), and ReLU activation.\n- MaxPooling2D layer with a pool size of (2,2).\n- Third Convolution Block:\n- 3 Conv2D layers with 256 filters, kernel size of (3,3), and ReLU activation.\n- MaxPooling2D layer with a pool size of (2,2).\n- Fourth Convolution Block:\n- 3 Conv2D layers with 512 filters, kernel size of (3,3), and ReLU activation.\n3. Flatten Layer:\n- Converts the 3D output of the convolutional layers to a 1D vector.\n4. Fully Connected Layers:\n- Two Dense layers with 4096 units each and ReLU activation.\n- Dropout layers with a dropout rate of 0.5 to prevent overfitting.\n5. Output Layer:\n- Dense layer with 2 units and softmax activation for binary classification.\n\n\n### Reasoning for the Architecture\n1. Depth of the Network:The depth allows the model to learn complex patterns and features from the images. The multiple layers of convolutions help capture different levels of abstraction, which is crucial for identifying subtle features indicative of metastatic cancer.\n\n2. Use of Dropout:\nDropout is used to prevent overfitting, especially since the dataset is relatively small. Dropout randomly sets a fraction of input units to 0 at each update during training time, which helps prevent the network from becoming too reliant on any particular neurons.\n\n3. Pooling Layers:\nMaxPooling layers reduce the spatial dimensions of the feature maps, which decreases computational complexity and helps the network become invariant to small translations in the input images.\n\n4. Large Dense Layers:\nThe large fully connected layers towards the end help in learning high-level representations. The model can combine the features extracted by the convolutional layers to make the final classification.\n","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameter Tuning and Alternative Architectures\n### We will experiment with several hyperparameters and architectures to find the optimal configuration:\n\n1. Learning Rate\n2. Batch Size\n3. Number of Filters in Convolutional Layers\n4. Dropout Rates\nWe'll compare three different architectures: the initial model, a simpler model, and a more complex model.","metadata":{}},{"cell_type":"markdown","source":"### Simpler Model","metadata":{}},{"cell_type":"code","source":"simpler_model = Sequential()\nsimpler_model.add(Conv2D(32, kernel_size, activation='relu', padding='same', input_shape=(96, 96, 3)))\nsimpler_model.add(MaxPooling2D(pool_size=pool_size))\nsimpler_model.add(Conv2D(64, kernel_size, activation='relu', padding='same'))\nsimpler_model.add(MaxPooling2D(pool_size=pool_size))\nsimpler_model.add(Flatten())\nsimpler_model.add(Dense(512, activation='relu'))\nsimpler_model.add(Dropout(dropout_dense))\nsimpler_model.add(Dense(2, activation='softmax'))\nsimpler_model.compile(Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['AUC'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Complex Model","metadata":{}},{"cell_type":"code","source":"complex_model = Sequential()\ncomplex_model.add(Conv2D(64, kernel_size, activation='relu', padding='same', input_shape=(96, 96, 3)))\ncomplex_model.add(Conv2D(64, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(MaxPooling2D(pool_size=pool_size)) \n\ncomplex_model.add(Conv2D(128, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(128, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(MaxPooling2D(pool_size=pool_size))\n\ncomplex_model.add(Conv2D(256, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(256, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(256, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(MaxPooling2D(pool_size=pool_size))\n\ncomplex_model.add(Conv2D(512, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(512, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(512, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(MaxPooling2D(pool_size=pool_size))\n\ncomplex_model.add(Conv2D(1024, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(1024, kernel_size, activation='relu', padding='same'))\ncomplex_model.add(Conv2D(1024, kernel_size, activation='relu', padding='same'))\n\ncomplex_model.add(Flatten())\ncomplex_model.add(Dense(4096, activation='relu'))\ncomplex_model.add(Dropout(dropout_dense))\ncomplex_model.add(Dense(4096, activation='relu'))\ncomplex_model.add(Dropout(dropout_dense))\ncomplex_model.add(Dense(2, activation='softmax'))\n\ncomplex_model.compile(Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['AUC'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_simpler = simpler_model.fit(train_gen, validation_data=val_gen, epochs=10, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_complex = complex_model.fit(train_gen, validation_data=val_gen, epochs=10, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_acc = history.history['AUC']\nval_acc = history.history['val_AUC']\n\nepoc = range(1, len(tr_acc) + 1)\n\nplt.plot(epoc, tr_acc, label='Training acc')\nplt.plot(epoc, val_acc, label='Validation acc')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_gen, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds = pd.DataFrame(predictions, columns=['0', '1'])\n\ndf_preds.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds[df_preds['1']>0.5]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds['file_names'] = test_gen.filenames","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_preds['id'] = df_preds['file_names'].str[5:-4]\ndf_preds[['id','1']].rename(columns={'1':'label'}).to_csv('submission.csv', columns=['id','label'],index=False) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]}]}